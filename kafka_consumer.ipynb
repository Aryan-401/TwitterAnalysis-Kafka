{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Kernal\n"
     ]
    }
   ],
   "source": [
    "print(\"Load Kernal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database is locked')).History will not be written to the database.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "import psycopg2\n",
    "import os\n",
    "import urllib.parse as up\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = KafkaConsumer(\n",
    "    'tweets',\n",
    "    bootstrap_servers=['localhost:9092'],\n",
    "    value_deserializer=lambda x: json.loads(x.decode('utf-8'))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REDACTED\n"
     ]
    }
   ],
   "source": [
    "up.uses_netloc.append(\"postgres\")\n",
    "print(os.getenv(\"DATABASE_URL\"))\n",
    "url = up.urlparse(os.getenv(\"DATABASE_URL\"))\n",
    "conn = psycopg2.connect(database=url.path[1:],\n",
    "user=url.username,\n",
    "password=url.password,\n",
    "host=url.hostname,\n",
    "port=url.port\n",
    ")\n",
    "\n",
    "conn.cursor().execute(\"Drop TABLE IF EXISTS Sentiments;\")\n",
    "\n",
    "conn.cursor().execute(\"\"\"CREATE TABLE Sentiments (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    sentiment VARCHAR(255) NOT NULL,\n",
    "    content TEXT NOT NULL,\n",
    "    user_id VARCHAR(50) NOT NULL,\n",
    "    sentiment_simplified VARCHAR(50) NOT NULL\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records: 100\n",
      "Records: 200\n",
      "Records: 300\n",
      "Records: 400\n",
      "Records: 500\n",
      "Records: 600\n",
      "Records: 700\n",
      "Records: 800\n",
      "Records: 900\n",
      "Records: 1000\n",
      "Records: 1100\n",
      "Records: 1200\n",
      "Records: 1300\n",
      "Records: 1400\n",
      "Records: 1500\n",
      "Records: 1600\n",
      "Records: 1700\n",
      "Records: 1800\n",
      "Records: 1900\n",
      "Records: 2000\n",
      "Records: 2100\n",
      "Records: 2200\n",
      "Records: 2300\n",
      "Records: 2400\n",
      "Records: 2500\n",
      "Records: 2600\n",
      "Records: 2700\n",
      "Records: 2800\n",
      "Records: 2900\n",
      "Records: 3000\n",
      "Records: 3100\n",
      "Records: 3200\n",
      "Records: 3300\n",
      "Records: 3400\n",
      "Records: 3500\n",
      "Records: 3600\n",
      "Records: 3700\n",
      "Records: 3800\n",
      "Records: 3900\n",
      "Records: 4000\n",
      "Records: 4100\n",
      "Records: 4200\n",
      "Records: 4300\n",
      "Records: 4400\n",
      "Records: 4500\n",
      "Records: 4600\n",
      "Records: 4700\n",
      "Records: 4800\n",
      "Records: 4900\n",
      "Records: 5000\n",
      "Records: 5100\n",
      "Records: 5200\n",
      "Records: 5300\n",
      "Records: 5400\n",
      "Records: 5500\n",
      "Records: 5600\n",
      "Records: 5700\n",
      "Records: 5800\n",
      "Records: 5900\n",
      "Records: 6000\n",
      "Records: 6100\n",
      "Records: 6200\n",
      "Records: 6300\n",
      "Records: 6400\n",
      "Records: 6500\n",
      "Records: 6600\n",
      "Records: 6700\n",
      "Records: 6800\n",
      "Records: 6900\n",
      "Records: 7000\n",
      "Records: 7100\n",
      "Records: 7200\n",
      "Records: 7300\n",
      "Records: 7400\n",
      "Records: 7500\n",
      "Records: 7600\n",
      "Records: 7700\n",
      "Records: 7800\n",
      "Records: 7900\n",
      "Records: 8000\n",
      "Records: 8100\n",
      "Records: 8200\n",
      "Records: 8300\n",
      "Records: 8400\n",
      "Records: 8500\n",
      "Records: 8600\n",
      "Records: 8700\n",
      "Records: 8800\n",
      "Records: 8900\n",
      "Records: 9000\n",
      "Records: 9100\n",
      "Records: 9200\n",
      "Records: 9300\n",
      "Records: 9400\n",
      "Records: 9500\n",
      "Records: 9600\n",
      "Records: 9700\n",
      "Records: 9800\n",
      "Records: 9900\n",
      "Records: 10000\n",
      "Records: 10100\n",
      "Records: 10200\n",
      "Records: 10300\n",
      "Records: 10400\n",
      "Records: 10500\n",
      "Records: 10600\n",
      "Records: 10700\n",
      "Records: 10800\n",
      "Records: 10900\n",
      "Records: 11000\n",
      "Records: 11100\n",
      "Records: 11200\n",
      "Records: 11300\n",
      "Records: 11400\n",
      "Records: 11500\n",
      "Records: 11600\n",
      "Records: 11700\n",
      "Records: 11800\n",
      "Records: 11900\n",
      "Records: 12000\n",
      "Records: 12100\n",
      "Records: 12200\n",
      "Records: 12300\n",
      "Records: 12400\n",
      "Records: 12500\n",
      "Records: 12600\n",
      "Records: 12700\n",
      "Records: 12800\n",
      "Records: 12900\n",
      "Records: 13000\n",
      "Records: 13100\n",
      "Records: 13200\n",
      "Records: 13300\n",
      "Records: 13400\n",
      "Records: 13500\n",
      "Records: 13600\n",
      "Records: 13700\n",
      "Records: 13800\n",
      "Records: 13900\n",
      "Records: 14000\n",
      "Records: 14100\n",
      "Records: 14200\n",
      "Records: 14300\n",
      "Records: 14400\n",
      "Records: 14500\n",
      "Records: 14600\n",
      "Records: 14700\n",
      "Records: 14800\n",
      "Records: 14900\n",
      "Records: 15000\n",
      "Records: 15100\n",
      "Records: 15200\n",
      "Records: 15300\n",
      "Records: 15400\n",
      "Records: 15500\n",
      "Records: 15600\n",
      "Records: 15700\n",
      "Records: 15800\n",
      "Records: 15900\n",
      "Records: 16000\n",
      "Records: 16100\n",
      "Records: 16200\n",
      "Records: 16300\n",
      "Records: 16400\n",
      "Records: 16500\n",
      "Records: 16600\n",
      "Records: 16700\n",
      "Records: 16800\n",
      "Records: 16900\n",
      "Records: 17000\n",
      "Records: 17100\n",
      "Records: 17200\n",
      "Records: 17300\n",
      "Records: 17400\n",
      "Records: 17500\n",
      "Records: 17600\n",
      "Records: 17700\n",
      "Records: 17800\n",
      "Records: 17900\n",
      "Records: 18000\n",
      "Records: 18100\n",
      "Records: 18200\n",
      "Records: 18300\n",
      "Records: 18400\n",
      "Records: 18500\n",
      "Records: 18600\n",
      "Records: 18700\n",
      "Records: 18800\n",
      "Records: 18900\n",
      "Records: 19000\n",
      "Records: 19100\n",
      "Records: 19200\n",
      "Records: 19300\n",
      "Records: 19400\n",
      "Records: 19500\n",
      "Records: 19600\n",
      "Records: 19700\n",
      "Records: 19800\n",
      "Records: 19900\n",
      "Records: 20000\n",
      "Records: 20100\n",
      "Records: 20200\n",
      "Records: 20300\n",
      "Records: 20400\n",
      "Records: 20500\n",
      "Records: 20600\n",
      "Records: 20700\n",
      "Records: 20800\n",
      "Records: 20900\n",
      "Records: 21000\n",
      "Records: 21100\n",
      "Records: 21200\n",
      "Records: 21300\n",
      "Records: 21400\n",
      "Records: 21500\n",
      "Records: 21600\n",
      "Records: 21700\n",
      "Records: 21800\n",
      "Records: 21900\n",
      "Records: 22000\n",
      "Records: 22100\n",
      "Records: 22200\n",
      "Records: 22300\n",
      "Records: 22400\n",
      "Records: 22500\n",
      "Records: 22600\n",
      "Records: 22700\n",
      "Records: 22800\n",
      "Records: 22900\n",
      "Records: 23000\n",
      "Records: 23100\n",
      "Records: 23200\n",
      "Records: 23300\n",
      "Records: 23400\n",
      "Records: 23500\n",
      "Records: 23600\n",
      "Records: 23700\n",
      "Records: 23800\n",
      "Records: 23900\n",
      "Records: 24000\n",
      "Records: 24100\n",
      "Records: 24200\n",
      "Records: 24300\n",
      "Records: 24400\n",
      "Records: 24500\n",
      "Records: 24600\n",
      "Records: 24700\n",
      "Records: 24800\n",
      "Records: 24900\n",
      "Records: 25000\n",
      "Records: 25100\n",
      "Records: 25200\n",
      "Records: 25300\n",
      "Records: 25400\n",
      "Records: 25500\n",
      "Records: 25600\n",
      "Records: 25700\n",
      "Records: 25800\n",
      "Records: 25900\n",
      "Records: 26000\n",
      "Records: 26100\n",
      "Records: 26200\n",
      "Records: 26300\n",
      "Records: 26400\n",
      "Records: 26500\n",
      "Records: 26600\n",
      "Records: 26700\n",
      "Records: 26800\n",
      "Records: 26900\n",
      "Records: 27000\n",
      "Records: 27100\n",
      "Records: 27200\n",
      "Records: 27300\n",
      "Records: 27400\n",
      "Records: 27500\n",
      "Records: 27600\n",
      "Records: 27700\n",
      "Records: 27800\n",
      "Records: 27900\n",
      "Records: 28000\n",
      "Records: 28100\n",
      "Records: 28200\n",
      "Records: 28300\n",
      "Records: 28400\n",
      "Records: 28500\n",
      "Records: 28600\n",
      "Records: 28700\n",
      "Records: 28800\n",
      "Records: 28900\n",
      "Records: 29000\n",
      "Records: 29100\n",
      "Records: 29200\n",
      "Records: 29300\n",
      "Records: 29400\n",
      "Records: 29500\n",
      "Records: 29600\n",
      "Records: 29700\n",
      "Records: 29800\n",
      "Records: 29900\n",
      "Records: 30000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/aryan401/Development/TwitterAnalysis/kafka_consumer.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aryan401/Development/TwitterAnalysis/kafka_consumer.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m count \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/aryan401/Development/TwitterAnalysis/kafka_consumer.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m consumer:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aryan401/Development/TwitterAnalysis/kafka_consumer.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     c_val \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mJSONDecoder()\u001b[39m.\u001b[39mdecode(c\u001b[39m.\u001b[39mvalue)[\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aryan401/Development/TwitterAnalysis/kafka_consumer.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     conn\u001b[39m.\u001b[39mcursor()\u001b[39m.\u001b[39mexecute(\u001b[39m\"\u001b[39m\u001b[39mINSERT INTO Sentiments (sentiment, content, user_id, sentiment_simplified) VALUES (\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m, (c_val[\u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m], c_val[\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m], c_val[\u001b[39m'\u001b[39m\u001b[39muser_id\u001b[39m\u001b[39m'\u001b[39m], c_val[\u001b[39m'\u001b[39m\u001b[39msentiment_simplified\u001b[39m\u001b[39m'\u001b[39m]))\n",
      "File \u001b[0;32m~/anaconda3/envs/data_env/lib/python3.8/site-packages/kafka/consumer/group.py:1193\u001b[0m, in \u001b[0;36mKafkaConsumer.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnext_v1()\n\u001b[1;32m   1192\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1193\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext_v2()\n",
      "File \u001b[0;32m~/anaconda3/envs/data_env/lib/python3.8/site-packages/kafka/consumer/group.py:1201\u001b[0m, in \u001b[0;36mKafkaConsumer.next_v2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_generator_v2()\n\u001b[1;32m   1200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator)\n\u001b[1;32m   1202\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m   1203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/data_env/lib/python3.8/site-packages/kafka/consumer/group.py:1116\u001b[0m, in \u001b[0;36mKafkaConsumer._message_generator_v2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_message_generator_v2\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1115\u001b[0m     timeout_ms \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m \u001b[39m*\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consumer_timeout \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mtime())\n\u001b[0;32m-> 1116\u001b[0m     record_map \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpoll(timeout_ms\u001b[39m=\u001b[39;49mtimeout_ms, update_offsets\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m   1117\u001b[0m     \u001b[39mfor\u001b[39;00m tp, records \u001b[39min\u001b[39;00m six\u001b[39m.\u001b[39miteritems(record_map):\n\u001b[1;32m   1118\u001b[0m         \u001b[39m# Generators are stateful, and it is possible that the tp / records\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m         \u001b[39m# here may become stale during iteration -- i.e., we seek to a\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m         \u001b[39m# different offset, pause consumption, or lose assignment.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m         \u001b[39mfor\u001b[39;00m record \u001b[39min\u001b[39;00m records:\n\u001b[1;32m   1122\u001b[0m             \u001b[39m# is_fetchable(tp) should handle assignment changes and offset\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m             \u001b[39m# resets; for all other changes (e.g., seeks) we'll rely on the\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m             \u001b[39m# outer function destroying the existing iterator/generator\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m             \u001b[39m# via self._iterator = None\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/data_env/lib/python3.8/site-packages/kafka/consumer/group.py:655\u001b[0m, in \u001b[0;36mKafkaConsumer.poll\u001b[0;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[1;32m    653\u001b[0m remaining \u001b[39m=\u001b[39m timeout_ms\n\u001b[1;32m    654\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 655\u001b[0m     records \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll_once(remaining, max_records, update_offsets\u001b[39m=\u001b[39;49mupdate_offsets)\n\u001b[1;32m    656\u001b[0m     \u001b[39mif\u001b[39;00m records:\n\u001b[1;32m    657\u001b[0m         \u001b[39mreturn\u001b[39;00m records\n",
      "File \u001b[0;32m~/anaconda3/envs/data_env/lib/python3.8/site-packages/kafka/consumer/group.py:702\u001b[0m, in \u001b[0;36mKafkaConsumer._poll_once\u001b[0;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mpoll(timeout_ms\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    701\u001b[0m timeout_ms \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(timeout_ms, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_coordinator\u001b[39m.\u001b[39mtime_to_next_poll() \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m)\n\u001b[0;32m--> 702\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49mpoll(timeout_ms\u001b[39m=\u001b[39;49mtimeout_ms)\n\u001b[1;32m    703\u001b[0m \u001b[39m# after the long poll, we should check whether the group needs to rebalance\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[39m# prior to returning data so that the group can stabilize faster\u001b[39;00m\n\u001b[1;32m    705\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_coordinator\u001b[39m.\u001b[39mneed_rejoin():\n",
      "File \u001b[0;32m~/anaconda3/envs/data_env/lib/python3.8/site-packages/kafka/client_async.py:602\u001b[0m, in \u001b[0;36mKafkaClient.poll\u001b[0;34m(self, timeout_ms, future)\u001b[0m\n\u001b[1;32m    599\u001b[0m             timeout \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(timeout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mretry_backoff_ms\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    600\u001b[0m         timeout \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39m0\u001b[39m, timeout)  \u001b[39m# avoid negative timeouts\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout \u001b[39m/\u001b[39;49m \u001b[39m1000\u001b[39;49m)\n\u001b[1;32m    604\u001b[0m \u001b[39m# called without the lock to avoid deadlock potential\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \u001b[39m# if handlers need to acquire locks\u001b[39;00m\n\u001b[1;32m    606\u001b[0m responses\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fire_pending_completed_requests())\n",
      "File \u001b[0;32m~/anaconda3/envs/data_env/lib/python3.8/site-packages/kafka/client_async.py:634\u001b[0m, in \u001b[0;36mKafkaClient._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_register_send_sockets()\n\u001b[1;32m    633\u001b[0m start_select \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 634\u001b[0m ready \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    635\u001b[0m end_select \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sensors:\n",
      "File \u001b[0;32m~/anaconda3/envs/data_env/lib/python3.8/selectors.py:468\u001b[0m, in \u001b[0;36mEpollSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    466\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    467\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 468\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout, max_ev)\n\u001b[1;32m    469\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "for c in consumer:\n",
    "    c_val = json.decoder.JSONDecoder().decode(c.value)[0]\n",
    "    conn.cursor().execute(\"INSERT INTO Sentiments (sentiment, content, user_id, sentiment_simplified) VALUES (%s, %s, %s, %s)\", (c_val['sentiment'], c_val['content'], c_val['user_id'], c_val['sentiment_simplified']))\n",
    "    count+= 1\n",
    "    if (count % 100 ==0):\n",
    "        conn.commit()\n",
    "        print(f\"Records: {count}\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
